{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jakub Bandurski, Michał Bryzik, Kacper Gruca\n",
    "## Text Mining and Social Media Mining Project\n",
    "## Can sentiment analysis predict the subreddit r/AITA top comment verdict?\n",
    "## What are the most common topics on this subreddit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of verdicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_body</th>\n",
       "      <th>C1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(non specific conflict) Telemarketers vs. Phon...</td>\n",
       "      <td>&lt;|response|&gt; Yes, you are the asshole, with ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIAA, Disabled CSGO player who found another \"...</td>\n",
       "      <td>&lt;|response|&gt; Why would you be the asshole? You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AITA \"...You left this marriage for your own s...</td>\n",
       "      <td>&lt;|response|&gt; YTA. It's only been three months ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AITA \"Friend\" called me narcissistic a**hole f...</td>\n",
       "      <td>&lt;|response|&gt; Judging from the situation and yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AITA \"Friends\" argue with GF, now are mad at m...</td>\n",
       "      <td>&lt;|response|&gt; NTA Your “friends” are a bunch of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title_body  \\\n",
       "0  (non specific conflict) Telemarketers vs. Phon...   \n",
       "1  AIAA, Disabled CSGO player who found another \"...   \n",
       "2  AITA \"...You left this marriage for your own s...   \n",
       "3  AITA \"Friend\" called me narcissistic a**hole f...   \n",
       "4  AITA \"Friends\" argue with GF, now are mad at m...   \n",
       "\n",
       "                                                  C1  \n",
       "0  <|response|> Yes, you are the asshole, with ca...  \n",
       "1  <|response|> Why would you be the asshole? You...  \n",
       "2  <|response|> YTA. It's only been three months ...  \n",
       "3  <|response|> Judging from the situation and yo...  \n",
       "4  <|response|> NTA Your “friends” are a bunch of...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(\"./data/raw_data.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_body</th>\n",
       "      <th>C1</th>\n",
       "      <th>AITA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AITA \"...You left this marriage for your own s...</td>\n",
       "      <td>&lt;|response|&gt; YTA. It's only been three months ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AITA \"Friends\" argue with GF, now are mad at m...</td>\n",
       "      <td>&lt;|response|&gt; NTA Your “friends” are a bunch of...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AITA \"I gave you photo credit on the last coup...</td>\n",
       "      <td>&lt;|response|&gt; NTA - It sounds like he won't be ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AITA \"Selling out a coworker\" So, I'm gonna be...</td>\n",
       "      <td>&lt;|response|&gt; NTA. From what I understand, he u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AITA \"UNWELCOME IN MY OWN HOME\" This happened ...</td>\n",
       "      <td>&lt;|response|&gt; NTA - You should never feel unwel...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title_body  \\\n",
       "0  AITA \"...You left this marriage for your own s...   \n",
       "1  AITA \"Friends\" argue with GF, now are mad at m...   \n",
       "2  AITA \"I gave you photo credit on the last coup...   \n",
       "3  AITA \"Selling out a coworker\" So, I'm gonna be...   \n",
       "4  AITA \"UNWELCOME IN MY OWN HOME\" This happened ...   \n",
       "\n",
       "                                                  C1   AITA  \n",
       "0  <|response|> YTA. It's only been three months ...   True  \n",
       "1  <|response|> NTA Your “friends” are a bunch of...  False  \n",
       "2  <|response|> NTA - It sounds like he won't be ...  False  \n",
       "3  <|response|> NTA. From what I understand, he u...  False  \n",
       "4  <|response|> NTA - You should never feel unwel...  False  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = [\"YTA\",\"NTA\",\"ESH\",\"NAH\"]\n",
    "df[\"yes\"] = (df[\"C1\"].str.contains(\"YTA\")) | (df[\"C1\"].str.contains(\"ESH\"))\n",
    "df[\"no\"] = (df[\"C1\"].str.contains(\"NTA\")) | (df[\"C1\"].str.contains(\"NAH\"))\n",
    "df = df[(df[\"yes\"]==True)|(df[\"no\"]==True)]\n",
    "df[\"AITA\"] = df[\"yes\"]\n",
    "df = df.drop(labels=[\"yes\",\"no\"], axis=1).reset_index(drop=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the regex module\n",
    "import re\n",
    "\n",
    "# Define a function to clean text using regex\n",
    "def regex_clean(text):\n",
    "    # Remove all characters that are not alphanumeric, spaces, newlines, or periods\n",
    "    text = re.sub(\"[^a-zA-Z0-9' \\n\\.]\", '', text)\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    # Remove all characters that are not alphanumeric or spaces\n",
    "    text = re.sub(r\"[^\\w\\s']\",'', text)\n",
    "    \n",
    "    # Remove all digits\n",
    "    text = re.sub('\\d', '', text)\n",
    "    \n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Return the cleaned text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean columns\n",
    "df[\"C1_clean\"] = df[\"C1\"].apply(lambda x: regex_clean(x))\n",
    "df[\"title_body_clean\"] = df[\"title_body\"].apply(lambda x: regex_clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_body</th>\n",
       "      <th>C1</th>\n",
       "      <th>AITA</th>\n",
       "      <th>C1_clean</th>\n",
       "      <th>title_body_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AITA \"...You left this marriage for your own s...</td>\n",
       "      <td>&lt;|response|&gt; YTA. It's only been three months ...</td>\n",
       "      <td>True</td>\n",
       "      <td>response yta it's only been three months since...</td>\n",
       "      <td>aita you left this marriage for your own selfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AITA \"Friends\" argue with GF, now are mad at m...</td>\n",
       "      <td>&lt;|response|&gt; NTA Your “friends” are a bunch of...</td>\n",
       "      <td>False</td>\n",
       "      <td>response nta your friends are a bunch of assho...</td>\n",
       "      <td>aita friends argue with gf now are mad at me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AITA \"I gave you photo credit on the last coup...</td>\n",
       "      <td>&lt;|response|&gt; NTA - It sounds like he won't be ...</td>\n",
       "      <td>False</td>\n",
       "      <td>response nta it sounds like he won't be gettin...</td>\n",
       "      <td>aita i gave you photo credit on the last coupl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AITA \"Selling out a coworker\" So, I'm gonna be...</td>\n",
       "      <td>&lt;|response|&gt; NTA. From what I understand, he u...</td>\n",
       "      <td>False</td>\n",
       "      <td>response nta from what i understand he used a ...</td>\n",
       "      <td>aita selling out a coworker so i'm gonna be to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AITA \"UNWELCOME IN MY OWN HOME\" This happened ...</td>\n",
       "      <td>&lt;|response|&gt; NTA - You should never feel unwel...</td>\n",
       "      <td>False</td>\n",
       "      <td>response nta you should never feel unwelcomed ...</td>\n",
       "      <td>aita unwelcome in my own home this happened to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title_body  \\\n",
       "0  AITA \"...You left this marriage for your own s...   \n",
       "1  AITA \"Friends\" argue with GF, now are mad at m...   \n",
       "2  AITA \"I gave you photo credit on the last coup...   \n",
       "3  AITA \"Selling out a coworker\" So, I'm gonna be...   \n",
       "4  AITA \"UNWELCOME IN MY OWN HOME\" This happened ...   \n",
       "\n",
       "                                                  C1   AITA  \\\n",
       "0  <|response|> YTA. It's only been three months ...   True   \n",
       "1  <|response|> NTA Your “friends” are a bunch of...  False   \n",
       "2  <|response|> NTA - It sounds like he won't be ...  False   \n",
       "3  <|response|> NTA. From what I understand, he u...  False   \n",
       "4  <|response|> NTA - You should never feel unwel...  False   \n",
       "\n",
       "                                            C1_clean  \\\n",
       "0  response yta it's only been three months since...   \n",
       "1  response nta your friends are a bunch of assho...   \n",
       "2  response nta it sounds like he won't be gettin...   \n",
       "3  response nta from what i understand he used a ...   \n",
       "4  response nta you should never feel unwelcomed ...   \n",
       "\n",
       "                                    title_body_clean  \n",
       "0  aita you left this marriage for your own selfi...  \n",
       "1  aita friends argue with gf now are mad at me f...  \n",
       "2  aita i gave you photo credit on the last coupl...  \n",
       "3  aita selling out a coworker so i'm gonna be to...  \n",
       "4  aita unwelcome in my own home this happened to...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "# remove additional subject-specific stopwards\n",
    "for el in [\"aita\",\"response\",\"yta\",\"nta\",\"esh\",\"nah\",\"asshole\",\"a**hole\",\n",
    "            \"'m\",\"'s\",\"n't\",\"'d\",\"'t\",\"'ve\",\"'ll\",\"'re\",\"'em\",\"'nt\",\"'d'nt\",\"'t'nt\",\n",
    "            \"'ve'nt\",\"'ll'nt\",\"'re'nt\",\"'em'nt\"]:\n",
    "    stop_words.add(el)\n",
    "for sw in stop_words:\n",
    "    if \"'\" in sw:\n",
    "        sw.replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "def remove_stopwords(text, word_tokenizer=word_tokenize, stop_words=stop_words):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    return \" \".join([w for w in word_tokens if not w in stop_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from columns\n",
    "df[\"C1_no_stopwords\"] = df[\"C1_clean\"].apply(lambda x: remove_stopwords(text=x,word_tokenizer=word_tokenize, stop_words=stop_words))\n",
    "df[\"title_body_no_stopwords\"] = df[\"title_body_clean\"].apply(lambda x: remove_stopwords(text=x,word_tokenizer=word_tokenize, stop_words=stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_body</th>\n",
       "      <th>C1</th>\n",
       "      <th>AITA</th>\n",
       "      <th>C1_clean</th>\n",
       "      <th>title_body_clean</th>\n",
       "      <th>C1_no_stopwords</th>\n",
       "      <th>title_body_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AITA \"...You left this marriage for your own s...</td>\n",
       "      <td>&lt;|response|&gt; YTA. It's only been three months ...</td>\n",
       "      <td>True</td>\n",
       "      <td>response yta it's only been three months since...</td>\n",
       "      <td>aita you left this marriage for your own selfi...</td>\n",
       "      <td>three months since bf split wife divorce two a...</td>\n",
       "      <td>left marriage selfish right happy think thats ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AITA \"Friends\" argue with GF, now are mad at m...</td>\n",
       "      <td>&lt;|response|&gt; NTA Your “friends” are a bunch of...</td>\n",
       "      <td>False</td>\n",
       "      <td>response nta your friends are a bunch of assho...</td>\n",
       "      <td>aita friends argue with gf now are mad at me f...</td>\n",
       "      <td>friends bunch assholes obviously endoftext</td>\n",
       "      <td>friends argue gf mad siding hey first time pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AITA \"I gave you photo credit on the last coup...</td>\n",
       "      <td>&lt;|response|&gt; NTA - It sounds like he won't be ...</td>\n",
       "      <td>False</td>\n",
       "      <td>response nta it sounds like he won't be gettin...</td>\n",
       "      <td>aita i gave you photo credit on the last coupl...</td>\n",
       "      <td>sounds like wo getting photos anytime soon end...</td>\n",
       "      <td>gave photo credit last couple since whole flar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AITA \"Selling out a coworker\" So, I'm gonna be...</td>\n",
       "      <td>&lt;|response|&gt; NTA. From what I understand, he u...</td>\n",
       "      <td>False</td>\n",
       "      <td>response nta from what i understand he used a ...</td>\n",
       "      <td>aita selling out a coworker so i'm gonna be to...</td>\n",
       "      <td>understand used racial slur attempted avoid co...</td>\n",
       "      <td>selling coworker gon na totally honest bc want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AITA \"UNWELCOME IN MY OWN HOME\" This happened ...</td>\n",
       "      <td>&lt;|response|&gt; NTA - You should never feel unwel...</td>\n",
       "      <td>False</td>\n",
       "      <td>response nta you should never feel unwelcomed ...</td>\n",
       "      <td>aita unwelcome in my own home this happened to...</td>\n",
       "      <td>never feel unwelcomed home even partner feels ...</td>\n",
       "      <td>unwelcome home happened today still working he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title_body  \\\n",
       "0  AITA \"...You left this marriage for your own s...   \n",
       "1  AITA \"Friends\" argue with GF, now are mad at m...   \n",
       "2  AITA \"I gave you photo credit on the last coup...   \n",
       "3  AITA \"Selling out a coworker\" So, I'm gonna be...   \n",
       "4  AITA \"UNWELCOME IN MY OWN HOME\" This happened ...   \n",
       "\n",
       "                                                  C1   AITA  \\\n",
       "0  <|response|> YTA. It's only been three months ...   True   \n",
       "1  <|response|> NTA Your “friends” are a bunch of...  False   \n",
       "2  <|response|> NTA - It sounds like he won't be ...  False   \n",
       "3  <|response|> NTA. From what I understand, he u...  False   \n",
       "4  <|response|> NTA - You should never feel unwel...  False   \n",
       "\n",
       "                                            C1_clean  \\\n",
       "0  response yta it's only been three months since...   \n",
       "1  response nta your friends are a bunch of assho...   \n",
       "2  response nta it sounds like he won't be gettin...   \n",
       "3  response nta from what i understand he used a ...   \n",
       "4  response nta you should never feel unwelcomed ...   \n",
       "\n",
       "                                    title_body_clean  \\\n",
       "0  aita you left this marriage for your own selfi...   \n",
       "1  aita friends argue with gf now are mad at me f...   \n",
       "2  aita i gave you photo credit on the last coupl...   \n",
       "3  aita selling out a coworker so i'm gonna be to...   \n",
       "4  aita unwelcome in my own home this happened to...   \n",
       "\n",
       "                                     C1_no_stopwords  \\\n",
       "0  three months since bf split wife divorce two a...   \n",
       "1         friends bunch assholes obviously endoftext   \n",
       "2  sounds like wo getting photos anytime soon end...   \n",
       "3  understand used racial slur attempted avoid co...   \n",
       "4  never feel unwelcomed home even partner feels ...   \n",
       "\n",
       "                             title_body_no_stopwords  \n",
       "0  left marriage selfish right happy think thats ...  \n",
       "1  friends argue gf mad siding hey first time pos...  \n",
       "2  gave photo credit last couple since whole flar...  \n",
       "3  selling coworker gon na totally honest bc want...  \n",
       "4  unwelcome home happened today still working he...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "def stemming(text,ps=PorterStemmer):\n",
    "    output = []\n",
    "    for word in text.split():\n",
    "        # if the word is not found in the stemmer don't stem it\n",
    "        try:\n",
    "            output.append(ps.stem(word))\n",
    "        except:\n",
    "            output.append(word)\n",
    "    return \" \".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from columns\n",
    "df[\"C1_stemmed\"] = df[\"C1_no_stopwords\"].apply(lambda x: stemming(text=x,ps=PorterStemmer))\n",
    "df[\"title_body_stemmed\"] = df[\"title_body_no_stopwords\"].apply(lambda x: stemming(text=x,ps=PorterStemmer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results\n",
    "Containing cleaned versions of posts and comments without stopwords as well as the stemmed versions of said posts and comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"title_body_no_stopwords\",\"C1_no_stopwords\",\"title_body_stemmed\",\"C1_stemmed\",\"AITA\"]].to_pickle(\"./data/cleaned_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_body_no_stopwords</th>\n",
       "      <th>C1_no_stopwords</th>\n",
       "      <th>title_body_stemmed</th>\n",
       "      <th>C1_stemmed</th>\n",
       "      <th>AITA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left marriage selfish right happy think thats ...</td>\n",
       "      <td>three months since bf split wife divorce two a...</td>\n",
       "      <td>left marriage selfish right happy think thats ...</td>\n",
       "      <td>three months since bf split wife divorce two a...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>friends argue gf mad siding hey first time pos...</td>\n",
       "      <td>friends bunch assholes obviously endoftext</td>\n",
       "      <td>friends argue gf mad siding hey first time pos...</td>\n",
       "      <td>friends bunch assholes obviously endoftext</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gave photo credit last couple since whole flar...</td>\n",
       "      <td>sounds like wo getting photos anytime soon end...</td>\n",
       "      <td>gave photo credit last couple since whole flar...</td>\n",
       "      <td>sounds like wo getting photos anytime soon end...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>selling coworker gon na totally honest bc want...</td>\n",
       "      <td>understand used racial slur attempted avoid co...</td>\n",
       "      <td>selling coworker gon na totally honest bc want...</td>\n",
       "      <td>understand used racial slur attempted avoid co...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unwelcome home happened today still working he...</td>\n",
       "      <td>never feel unwelcomed home even partner feels ...</td>\n",
       "      <td>unwelcome home happened today still working he...</td>\n",
       "      <td>never feel unwelcomed home even partner feels ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title_body_no_stopwords  \\\n",
       "0  left marriage selfish right happy think thats ...   \n",
       "1  friends argue gf mad siding hey first time pos...   \n",
       "2  gave photo credit last couple since whole flar...   \n",
       "3  selling coworker gon na totally honest bc want...   \n",
       "4  unwelcome home happened today still working he...   \n",
       "\n",
       "                                     C1_no_stopwords  \\\n",
       "0  three months since bf split wife divorce two a...   \n",
       "1         friends bunch assholes obviously endoftext   \n",
       "2  sounds like wo getting photos anytime soon end...   \n",
       "3  understand used racial slur attempted avoid co...   \n",
       "4  never feel unwelcomed home even partner feels ...   \n",
       "\n",
       "                                  title_body_stemmed  \\\n",
       "0  left marriage selfish right happy think thats ...   \n",
       "1  friends argue gf mad siding hey first time pos...   \n",
       "2  gave photo credit last couple since whole flar...   \n",
       "3  selling coworker gon na totally honest bc want...   \n",
       "4  unwelcome home happened today still working he...   \n",
       "\n",
       "                                          C1_stemmed   AITA  \n",
       "0  three months since bf split wife divorce two a...   True  \n",
       "1         friends bunch assholes obviously endoftext  False  \n",
       "2  sounds like wo getting photos anytime soon end...  False  \n",
       "3  understand used racial slur attempted avoid co...  False  \n",
       "4  never feel unwelcomed home even partner feels ...  False  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"title_body_no_stopwords\",\"C1_no_stopwords\",\"title_body_stemmed\",\"C1_stemmed\",\"AITA\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
