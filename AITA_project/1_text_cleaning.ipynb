{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jakub Bandurski, Michał Bryzik, Kacper Gruca\n",
    "## Text Mining and Social Media Mining Project\n",
    "## Can sentiment analysis predict the subreddit r/AITA top comment verdict?\n",
    "## What are the most common topics on this subreddit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of verdicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_body</th>\n",
       "      <th>C1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(non specific conflict) Telemarketers vs. Phon...</td>\n",
       "      <td>&lt;|response|&gt; Yes, you are the asshole, with ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIAA, Disabled CSGO player who found another \"...</td>\n",
       "      <td>&lt;|response|&gt; Why would you be the asshole? You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AITA \"...You left this marriage for your own s...</td>\n",
       "      <td>&lt;|response|&gt; YTA. It's only been three months ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AITA \"Friend\" called me narcissistic a**hole f...</td>\n",
       "      <td>&lt;|response|&gt; Judging from the situation and yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AITA \"Friends\" argue with GF, now are mad at m...</td>\n",
       "      <td>&lt;|response|&gt; NTA Your “friends” are a bunch of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title_body  \\\n",
       "0  (non specific conflict) Telemarketers vs. Phon...   \n",
       "1  AIAA, Disabled CSGO player who found another \"...   \n",
       "2  AITA \"...You left this marriage for your own s...   \n",
       "3  AITA \"Friend\" called me narcissistic a**hole f...   \n",
       "4  AITA \"Friends\" argue with GF, now are mad at m...   \n",
       "\n",
       "                                                  C1  \n",
       "0  <|response|> Yes, you are the asshole, with ca...  \n",
       "1  <|response|> Why would you be the asshole? You...  \n",
       "2  <|response|> YTA. It's only been three months ...  \n",
       "3  <|response|> Judging from the situation and yo...  \n",
       "4  <|response|> NTA Your “friends” are a bunch of...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(\"./data/raw_data.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_body</th>\n",
       "      <th>C1</th>\n",
       "      <th>AITA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AITA \"...You left this marriage for your own s...</td>\n",
       "      <td>&lt;|response|&gt; YTA. It's only been three months ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AITA \"Friends\" argue with GF, now are mad at m...</td>\n",
       "      <td>&lt;|response|&gt; NTA Your “friends” are a bunch of...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AITA \"I gave you photo credit on the last coup...</td>\n",
       "      <td>&lt;|response|&gt; NTA - It sounds like he won't be ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AITA \"Selling out a coworker\" So, I'm gonna be...</td>\n",
       "      <td>&lt;|response|&gt; NTA. From what I understand, he u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AITA \"UNWELCOME IN MY OWN HOME\" This happened ...</td>\n",
       "      <td>&lt;|response|&gt; NTA - You should never feel unwel...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title_body  \\\n",
       "0  AITA \"...You left this marriage for your own s...   \n",
       "1  AITA \"Friends\" argue with GF, now are mad at m...   \n",
       "2  AITA \"I gave you photo credit on the last coup...   \n",
       "3  AITA \"Selling out a coworker\" So, I'm gonna be...   \n",
       "4  AITA \"UNWELCOME IN MY OWN HOME\" This happened ...   \n",
       "\n",
       "                                                  C1   AITA  \n",
       "0  <|response|> YTA. It's only been three months ...   True  \n",
       "1  <|response|> NTA Your “friends” are a bunch of...  False  \n",
       "2  <|response|> NTA - It sounds like he won't be ...  False  \n",
       "3  <|response|> NTA. From what I understand, he u...  False  \n",
       "4  <|response|> NTA - You should never feel unwel...  False  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = [\"YTA\",\"NTA\",\"ESH\",\"NAH\"]\n",
    "df[\"yes\"] = (df[\"C1\"].str.contains(\"YTA\")) | (df[\"C1\"].str.contains(\"ESH\"))\n",
    "df[\"no\"] = (df[\"C1\"].str.contains(\"NTA\")) | (df[\"C1\"].str.contains(\"NAH\"))\n",
    "df = df[(df[\"yes\"]==True)|(df[\"no\"]==True)]\n",
    "df[\"AITA\"] = df[\"yes\"]\n",
    "df = df.drop(labels=[\"yes\",\"no\"], axis=1).reset_index(drop=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# clean text with regex\n",
    "def regex_clean(text):\n",
    "    text = re.sub('[^a-zA-Z0-9 \\n\\.]', '', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]','', text)\n",
    "    text = re.sub('\\d', '', text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean columns\n",
    "df[\"C1_clean\"] = df[\"C1\"].apply(lambda x: regex_clean(x))\n",
    "df[\"title_body_clean\"] = df[\"title_body\"].apply(lambda x: regex_clean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "# remove additional subject-specific stopwards\n",
    "for el in [\"aita\",\"response\",\"yta\",\"nta\",\"esh\",\"nah\",\"asshole\",\"a**hole\"]:\n",
    "    stop_words.add(el)\n",
    "for sw in stop_words:\n",
    "    if \"'\" in sw:\n",
    "        sw.replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "def remove_stopwords(text, word_tokenizer=word_tokenize, stop_words=stop_words):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    return \" \".join([w for w in word_tokens if not w in stop_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from columns\n",
    "df[\"C1_no_stopwords\"] = df[\"C1_clean\"].apply(lambda x: remove_stopwords(text=x,word_tokenizer=word_tokenize, stop_words=stop_words))\n",
    "df[\"title_body_no_stopwords\"] = df[\"title_body_clean\"].apply(lambda x: remove_stopwords(text=x,word_tokenizer=word_tokenize, stop_words=stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "def stemming(text,ps=PorterStemmer):\n",
    "    output = []\n",
    "    for word in text.split():\n",
    "        # if the word is not found in the stemmer don't stem it\n",
    "        try:\n",
    "            output.append(ps.stem(word))\n",
    "        except:\n",
    "            output.append(word)\n",
    "    return \" \".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from columns\n",
    "df[\"C1_stemmed\"] = df[\"C1_no_stopwords\"].apply(lambda x: stemming(text=x,ps=PorterStemmer))\n",
    "df[\"title_body_stemmed\"] = df[\"title_body_no_stopwords\"].apply(lambda x: stemming(text=x,ps=PorterStemmer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results\n",
    "Containing cleaned versions of posts and comments without stopwords as well as the stemmed versions of said posts and comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"title_body_no_stopwords\",\"C1_no_stopwords\",\"title_body_stemmed\",\"C1_stemmed\",\"AITA\"]].to_pickle(\"./data/cleaned_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_body_no_stopwords</th>\n",
       "      <th>C1_no_stopwords</th>\n",
       "      <th>title_body_stemmed</th>\n",
       "      <th>C1_stemmed</th>\n",
       "      <th>AITA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left marriage selfish right happy think thats ...</td>\n",
       "      <td>three months since bfs split wife didnt divorc...</td>\n",
       "      <td>left marriage selfish right happy think thats ...</td>\n",
       "      <td>three months since bfs split wife didnt divorc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>friends argue gf mad siding hey first time pos...</td>\n",
       "      <td>friends bunch assholes obviously endoftext</td>\n",
       "      <td>friends argue gf mad siding hey first time pos...</td>\n",
       "      <td>friends bunch assholes obviously endoftext</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gave photo credit last couple since whole flar...</td>\n",
       "      <td>sounds like wont getting photos anytime soon e...</td>\n",
       "      <td>gave photo credit last couple since whole flar...</td>\n",
       "      <td>sounds like wont getting photos anytime soon e...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>selling coworker im gon na totally honest bc w...</td>\n",
       "      <td>understand used racial slur attempted avoid co...</td>\n",
       "      <td>selling coworker im gon na totally honest bc w...</td>\n",
       "      <td>understand used racial slur attempted avoid co...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unwelcome home happened today still working he...</td>\n",
       "      <td>never feel unwelcomed home even partner feels ...</td>\n",
       "      <td>unwelcome home happened today still working he...</td>\n",
       "      <td>never feel unwelcomed home even partner feels ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title_body_no_stopwords  \\\n",
       "0  left marriage selfish right happy think thats ...   \n",
       "1  friends argue gf mad siding hey first time pos...   \n",
       "2  gave photo credit last couple since whole flar...   \n",
       "3  selling coworker im gon na totally honest bc w...   \n",
       "4  unwelcome home happened today still working he...   \n",
       "\n",
       "                                     C1_no_stopwords  \\\n",
       "0  three months since bfs split wife didnt divorc...   \n",
       "1         friends bunch assholes obviously endoftext   \n",
       "2  sounds like wont getting photos anytime soon e...   \n",
       "3  understand used racial slur attempted avoid co...   \n",
       "4  never feel unwelcomed home even partner feels ...   \n",
       "\n",
       "                                  title_body_stemmed  \\\n",
       "0  left marriage selfish right happy think thats ...   \n",
       "1  friends argue gf mad siding hey first time pos...   \n",
       "2  gave photo credit last couple since whole flar...   \n",
       "3  selling coworker im gon na totally honest bc w...   \n",
       "4  unwelcome home happened today still working he...   \n",
       "\n",
       "                                          C1_stemmed   AITA  \n",
       "0  three months since bfs split wife didnt divorc...   True  \n",
       "1         friends bunch assholes obviously endoftext  False  \n",
       "2  sounds like wont getting photos anytime soon e...  False  \n",
       "3  understand used racial slur attempted avoid co...  False  \n",
       "4  never feel unwelcomed home even partner feels ...  False  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"title_body_no_stopwords\",\"C1_no_stopwords\",\"title_body_stemmed\",\"C1_stemmed\",\"AITA\"]].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
